# @package _group_
interval: step
monitor: val_loss
frequency: 1
_target_: torch.optim.lr_scheduler.OneCycleLR
params:
  max_lr: ${optimizer.params.lr}
  epochs: ${trainer.params.max_epochs}
  steps_per_epoch: 'none'
  pct_start: 0.2
  div_factor: 1
  final_div_factor: 100
  anneal_strategy: cos
  #cycle_momentum: True
  #base_momentum: 0.85
  #max_momentum: 0.95
